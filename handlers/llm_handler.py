"""
LLMæ™ºèƒ½åˆ†æå¤„ç†å™¨
é›†æˆçœŸå®LLMæ¨¡å‹ï¼Œå®ç°æ™ºèƒ½é‡‘èæ•°æ®åˆ†æå’Œå»ºè®®ç”Ÿæˆ
æ”¯æŒåŸºäºè§„åˆ™çš„æœ¬åœ°åˆ†æå’ŒåŸºäºLLMçš„æ™ºèƒ½åˆ†æä¸¤ç§æ¨¡å¼
"""

import json
import logging
import re
import os
from typing import Dict, Any, List, Optional, Tuple, Union
from enum import Enum
from dataclasses import dataclass
import pandas as pd
import numpy as np

# LLMç›¸å…³å¯¼å…¥
try:
    import google.generativeai as genai
    from google.generativeai.types import (
        GenerationConfig, Tool, FunctionDeclaration,
        HarmCategory, HarmBlockThreshold, Part
    )
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False
    print("Warning: Google Generative AI not available. Using rule-based analysis only.")

from core.mcp_protocol import MCPRequest
from handlers.mcp_handler import handle_mcp_data_request, _get_and_normalize_akshare_data
from models.schemas import PaginatedDataResponse

logger = logging.getLogger("mcp-unified-service")

# --- LLMé…ç½®å’Œå·¥å…·å®šä¹‰ ---

def configure_llm():
    """é…ç½®LLMæ¨¡å‹"""
    if not LLM_AVAILABLE:
        return False

    try:
        gemini_api_key = os.environ.get("GEMINI_API_KEY")
        if not gemini_api_key:
            logger.warning("GEMINI_API_KEY not found in environment. LLM features disabled.")
            return False

        genai.configure(api_key=gemini_api_key)
        logger.info("LLM (Gemini) configured successfully")
        return True
    except Exception as e:
        logger.error(f"Failed to configure LLM: {e}")
        return False

# æ”¹è¿›çš„LLMé…ç½®ï¼ˆå€Ÿé‰´æ—§ç‰ˆæœ¬ï¼‰
def get_enhanced_generation_config():
    """è·å–å¢å¼ºçš„ç”Ÿæˆé…ç½®"""
    if not LLM_AVAILABLE:
        return None

    return GenerationConfig(
        temperature=0.1,  # æ›´ä½çš„æ¸©åº¦ï¼Œæ›´ç¨³å®šçš„é‡‘èåˆ†æ
        top_p=0.95,
        top_k=64,
        max_output_tokens=8192,  # æ›´å¤§çš„è¾“å‡ºé™åˆ¶
        response_mime_type="text/plain",
    )

def get_safety_settings():
    """è·å–å®‰å…¨è®¾ç½®"""
    if not LLM_AVAILABLE:
        return None

    return {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }

# å®šä¹‰AkShareæ•°æ®è·å–å·¥å…·
def create_akshare_tool():
    """åˆ›å»ºAkShareæ•°æ®è·å–å·¥å…·å®šä¹‰"""
    get_akshare_data_func = FunctionDeclaration(
        name="get_akshare_data",
        description="æ ¹æ®æ¥å£åç§°å’Œå‚æ•°ä»AkShareè·å–ä¸­å›½é‡‘èå¸‚åœºæ•°æ®ã€‚æ”¯æŒè‚¡ç¥¨ã€åŸºé‡‘ã€æŒ‡æ•°ã€å®è§‚ç»æµç­‰å„ç±»æ•°æ®ã€‚",
        parameters={
            "type": "object",
            "properties": {
                "interface": {
                    "type": "string",
                    "description": "è¦è°ƒç”¨çš„AkShareæ¥å£åç§°ã€‚ä¾‹å¦‚: 'stock_zh_a_hist'(Aè‚¡å†å²æ•°æ®), 'stock_zh_a_spot_em'(Aè‚¡å®æ—¶æ•°æ®), 'index_zh_a_hist'(æŒ‡æ•°æ•°æ®), 'macro_china_gdp'(GDPæ•°æ®)ç­‰ã€‚",
                },
                "params": {
                    "type": "object",
                    "description": "æ¥å£æ‰€éœ€å‚æ•°çš„å­—å…¸ã€‚ä¾‹å¦‚: {'symbol': '000001', 'period': 'daily', 'start_date': '20240101', 'end_date': '20241231'}",
                },
            },
            "required": ["interface", "params"],
        },
    )

    return Tool(function_declarations=[get_akshare_data_func])

def load_and_format_interfaces():
    """åŠ è½½å¹¶æ ¼å¼åŒ–æ¥å£æè¿°ä¾›LLMä½¿ç”¨"""
    try:
        with open("akshare_interfaces.json", "r", encoding="utf-8") as f:
            interfaces = json.load(f)

        formatted_string = "å¯ç”¨çš„AkShareæ¥å£åˆ—è¡¨å¦‚ä¸‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·é—®é¢˜é€‰æ‹©æœ€åˆé€‚çš„æ¥å£ï¼š\n\n"
        for endpoint in interfaces.get("endpoints", []):
            name = endpoint.get("name")
            description = endpoint.get("description")
            params = endpoint.get("input", {})
            param_str = ", ".join([f"{k}: {v}" for k, v in params.items()])
            formatted_string += f"- æ¥å£: '{name}'\n"
            formatted_string += f"  æè¿°: {description}\n"
            if param_str:
                formatted_string += f"  å‚æ•°: {param_str}\n"
            formatted_string += "\n"
        return formatted_string
    except Exception as e:
        logger.error(f"Error loading interfaces: {e}")
        return "æ— æ³•åŠ è½½æ¥å£åˆ—è¡¨ã€‚\n"

def get_enhanced_system_instructions():
    """è·å–å¢å¼ºçš„ç³»ç»ŸæŒ‡ä»¤ï¼ˆå€Ÿé‰´æ—§ç‰ˆæœ¬çš„ä¼˜ç§€è®¾è®¡ï¼‰"""
    tool_descriptions = load_and_format_interfaces()

    return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­å›½é‡‘èå¸‚åœºæ•°æ®åˆ†æåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·è·å–å’Œåˆ†æé‡‘èæ•°æ®ã€‚

**æ ¸å¿ƒèŒè´£ï¼š**
1. **ç†è§£ç”¨æˆ·éœ€æ±‚** - å‡†ç¡®è¯†åˆ«ç”¨æˆ·æƒ³è¦çš„å…·ä½“é‡‘èæ•°æ®ç±»å‹
2. **é€‰æ‹©åˆé€‚æ¥å£** - ä»ä¸‹é¢çš„AkShareæ¥å£åˆ—è¡¨ä¸­é€‰æ‹©æœ€é€‚åˆçš„æ¥å£
3. **æ„å»ºå‚æ•°å­—å…¸** - ä¸ºé€‰å®šçš„æ¥å£æ„å»ºæ­£ç¡®çš„å‚æ•°
4. **è°ƒç”¨æ•°æ®å·¥å…·** - ä½¿ç”¨get_akshare_dataå·¥å…·è·å–æ•°æ®
5. **ä¸“ä¸šåˆ†æ** - å¯¹è·å–çš„æ•°æ®è¿›è¡Œä¸“ä¸šçš„é‡‘èåˆ†æ
6. **æä¾›å»ºè®®** - åŸºäºæ•°æ®åˆ†æç»™å‡ºæŠ•èµ„å»ºè®®å’Œé£é™©æç¤º

**åˆ†æåŸåˆ™ï¼š**
- ä¿æŒå®¢è§‚å’Œä¸“ä¸šçš„åˆ†ææ€åº¦
- åŸºäºæ•°æ®äº‹å®è¿›è¡Œåˆ†æï¼Œé¿å…ä¸»è§‚è‡†æµ‹
- æä¾›å…·ä½“çš„æ•°å­—å’Œæ¯”ä¾‹æ”¯æŒç»“è®º
- æ˜ç¡®æŒ‡å‡ºæ•°æ®çš„æ—¶é—´èŒƒå›´å’Œå±€é™æ€§
- ç»™å‡ºé£é™©æç¤ºå’ŒæŠ•èµ„å»ºè®®æ—¶è¦è°¨æ…

**å¯ç”¨çš„AkShareæ¥å£ï¼š**
{tool_descriptions}

**é‡è¦æé†’ï¼š**
- å¦‚æœå·¥å…·è¿”å›æ•°æ®ï¼Œè¯·è¿›è¡Œæ·±å…¥çš„ä¸“ä¸šåˆ†æ
- å¦‚æœå·¥å…·è¿”å›é”™è¯¯ï¼Œè¯·æ¸…æ¥šåœ°å‘ŠçŸ¥ç”¨æˆ·å¹¶å»ºè®®æ›¿ä»£æ–¹æ¡ˆ
- å§‹ç»ˆä»¥ç”¨æˆ·çš„æŠ•èµ„å®‰å…¨ä¸ºé¦–è¦è€ƒè™‘
"""

# å…¨å±€LLMé…ç½®çŠ¶æ€
LLM_CONFIGURED = configure_llm() if LLM_AVAILABLE else False

class IntentType(Enum):
    """ç”¨æˆ·æ„å›¾ç±»å‹"""
    STOCK_ANALYSIS = "stock_analysis"          # è‚¡ç¥¨åˆ†æ
    MARKET_OVERVIEW = "market_overview"        # å¸‚åœºæ¦‚è§ˆ
    FINANCIAL_METRICS = "financial_metrics"    # è´¢åŠ¡æŒ‡æ ‡
    TREND_ANALYSIS = "trend_analysis"          # è¶‹åŠ¿åˆ†æ
    COMPARISON = "comparison"                  # å¯¹æ¯”åˆ†æ
    RECOMMENDATION = "recommendation"          # æŠ•èµ„å»ºè®®
    RISK_ASSESSMENT = "risk_assessment"        # é£é™©è¯„ä¼°
    UNKNOWN = "unknown"                        # æœªçŸ¥æ„å›¾

@dataclass
class AnalysisContext:
    """åˆ†æä¸Šä¸‹æ–‡"""
    intent: IntentType
    entities: Dict[str, Any]  # æå–çš„å®ä½“ï¼ˆè‚¡ç¥¨ä»£ç ã€æ—¶é—´èŒƒå›´ç­‰ï¼‰
    confidence: float         # æ„å›¾è¯†åˆ«ç½®ä¿¡åº¦
    raw_query: str           # åŸå§‹æŸ¥è¯¢

@dataclass
class AnalysisResult:
    """åˆ†æç»“æœ"""
    summary: str                    # åˆ†ææ‘˜è¦
    insights: List[str]            # å…³é”®æ´å¯Ÿ
    recommendations: List[str]      # å»ºè®®
    data_points: Dict[str, Any]    # å…³é”®æ•°æ®ç‚¹
    charts_suggested: List[str]    # å»ºè®®çš„å›¾è¡¨ç±»å‹
    risk_level: str               # é£é™©ç­‰çº§
    confidence: float             # åˆ†æç½®ä¿¡åº¦

class LLMAnalysisHandler:
    """å¢å¼ºçš„LLMæ™ºèƒ½åˆ†æå¤„ç†å™¨

    æ”¯æŒä¸¤ç§åˆ†ææ¨¡å¼ï¼š
    1. åŸºäºè§„åˆ™çš„æœ¬åœ°åˆ†æï¼ˆå¿«é€Ÿã€ç¦»çº¿ï¼‰
    2. åŸºäºLLMçš„æ™ºèƒ½åˆ†æï¼ˆå¼ºå¤§ã€éœ€è¦APIï¼‰
    """

    def __init__(self, use_llm: bool = True):
        self.use_llm = use_llm and LLM_CONFIGURED
        self.intent_patterns = self._load_intent_patterns()
        self.analysis_templates = self._load_analysis_templates()
        self._last_context = None

        # LLMç›¸å…³é…ç½®
        if self.use_llm:
            self.akshare_tool = create_akshare_tool()
            self.model_name = "gemini-1.5-flash-latest"
            logger.info("LLMåˆ†ææ¨¡å¼å·²å¯ç”¨")
        else:
            logger.info("ä½¿ç”¨åŸºäºè§„åˆ™çš„åˆ†ææ¨¡å¼")
    
    def _load_intent_patterns(self) -> Dict[IntentType, List[str]]:
        """åŠ è½½æ„å›¾è¯†åˆ«æ¨¡å¼"""
        return {
            IntentType.STOCK_ANALYSIS: [
                r"åˆ†æ.*?([0-9]{6})",
                r"([0-9]{6}).*?æ€ä¹ˆæ ·",
                r"([0-9]{6}).*?è¡¨ç°",
                r"æŸ¥çœ‹.*?([0-9]{6})",
                r"([\u4e00-\u9fa5]+).*?è‚¡ç¥¨.*?åˆ†æ"
            ],
            IntentType.MARKET_OVERVIEW: [
                r"å¸‚åœº.*?æ¦‚å†µ",
                r"å¤§ç›˜.*?æƒ…å†µ",
                r"æ•´ä½“.*?å¸‚åœº",
                r"ä»Šæ—¥.*?è¡Œæƒ…",
                r"å¸‚åœº.*?è¡¨ç°"
            ],
            IntentType.FINANCIAL_METRICS: [
                r"è´¢åŠ¡.*?æŒ‡æ ‡",
                r"PE.*?PB",
                r"å¸‚ç›ˆç‡",
                r"å‡€èµ„äº§æ”¶ç›Šç‡",
                r"ROE",
                r"è´¢æŠ¥.*?æ•°æ®"
            ],
            IntentType.TREND_ANALYSIS: [
                r"è¶‹åŠ¿.*?åˆ†æ",
                r"èµ°åŠ¿.*?å¦‚ä½•",
                r"æŠ€æœ¯.*?åˆ†æ",
                r"æœªæ¥.*?èµ°å‘",
                r"é¢„æµ‹.*?èµ°åŠ¿"
            ],
            IntentType.COMPARISON: [
                r"å¯¹æ¯”.*?([0-9]{6}).*?([0-9]{6})",
                r"æ¯”è¾ƒ.*?([0-9]{6}).*?([0-9]{6})",
                r"([0-9]{6}).*?vs.*?([0-9]{6})",
                r"å“ªä¸ª.*?æ›´å¥½"
            ],
            IntentType.RECOMMENDATION: [
                r"æ¨è.*?è‚¡ç¥¨",
                r"ä¹°å…¥.*?å»ºè®®",
                r"æŠ•èµ„.*?å»ºè®®",
                r"åº”è¯¥.*?ä¹°",
                r"å€¼å¾—.*?æŠ•èµ„"
            ],
            IntentType.RISK_ASSESSMENT: [
                r"é£é™©.*?è¯„ä¼°",
                r"é£é™©.*?å¦‚ä½•",
                r"å®‰å…¨.*?å—",
                r"é£é™©.*?å¤§å—",
                r"æŠ•èµ„.*?é£é™©"
            ]
        }
    
    def _load_analysis_templates(self) -> Dict[IntentType, Dict[str, Any]]:
        """åŠ è½½åˆ†ææ¨¡æ¿"""
        return {
            IntentType.STOCK_ANALYSIS: {
                "required_data": ["stock_zh_a_hist", "stock_zh_a_spot_em"],
                "analysis_points": [
                    "ä»·æ ¼è¶‹åŠ¿åˆ†æ",
                    "æˆäº¤é‡åˆ†æ", 
                    "æŠ€æœ¯æŒ‡æ ‡åˆ†æ",
                    "ç›¸å¯¹å¼ºå¼±åˆ†æ"
                ],
                "risk_factors": ["æ³¢åŠ¨ç‡", "æµåŠ¨æ€§", "åŸºæœ¬é¢é£é™©"]
            },
            IntentType.MARKET_OVERVIEW: {
                "required_data": ["stock_zh_a_spot_em", "index_zh_a_hist"],
                "analysis_points": [
                    "å¸‚åœºæ•´ä½“è¡¨ç°",
                    "è¡Œä¸šåˆ†å¸ƒ",
                    "æ¶¨è·Œæ¯”ä¾‹",
                    "æˆäº¤é‡åˆ†æ"
                ],
                "risk_factors": ["ç³»ç»Ÿæ€§é£é™©", "å¸‚åœºæƒ…ç»ª"]
            },
            IntentType.FINANCIAL_METRICS: {
                "required_data": ["stock_yjbb_em", "stock_financial_abstract"],
                "analysis_points": [
                    "ç›ˆåˆ©èƒ½åŠ›åˆ†æ",
                    "å¿å€ºèƒ½åŠ›åˆ†æ",
                    "è¿è¥æ•ˆç‡åˆ†æ",
                    "æˆé•¿æ€§åˆ†æ"
                ],
                "risk_factors": ["è´¢åŠ¡é£é™©", "ç»è¥é£é™©"]
            }
        }
    
    async def analyze_query(self, query: str, username: str = None) -> AnalysisResult:
        """åˆ†æç”¨æˆ·æŸ¥è¯¢å¹¶è¿”å›æ™ºèƒ½åˆ†æç»“æœ"""
        try:
            if self.use_llm:
                # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½åˆ†æ
                return await self._analyze_with_llm(query, username)
            else:
                # ä½¿ç”¨åŸºäºè§„åˆ™çš„åˆ†æ
                return await self._analyze_with_rules(query, username)

        except Exception as e:
            logger.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
            return AnalysisResult(
                summary="åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•",
                insights=["æ•°æ®è·å–å¤±è´¥"],
                recommendations=["è¯·æ£€æŸ¥æŸ¥è¯¢å‚æ•°"],
                data_points={},
                charts_suggested=[],
                risk_level="æœªçŸ¥",
                confidence=0.0
            )

    async def _analyze_with_llm(self, query: str, username: str = None) -> AnalysisResult:
        """ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½åˆ†æï¼ˆå€Ÿé‰´æ—§ç‰ˆæœ¬çš„ä¼˜ç§€è®¾è®¡ï¼‰"""
        try:
            # ä½¿ç”¨å¢å¼ºçš„é…ç½®åˆ›å»ºæ¨¡å‹
            model = genai.GenerativeModel(
                model_name="gemini-1.5-pro-latest",  # ä½¿ç”¨æ›´å¼ºå¤§çš„Proæ¨¡å‹
                generation_config=get_enhanced_generation_config(),
                safety_settings=get_safety_settings(),
                tools=[self.akshare_tool],
                system_instruction=get_enhanced_system_instructions()
            )

            # ä½¿ç”¨èŠå¤©ä¼šè¯ç®¡ç†ï¼ˆå€Ÿé‰´æ—§ç‰ˆæœ¬ï¼‰
            chat_session = model.start_chat()

            # å‘é€ç”¨æˆ·æŸ¥è¯¢åˆ°LLM
            response = chat_session.send_message(query)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ï¼ˆå€Ÿé‰´æ—§ç‰ˆæœ¬çš„ä¼˜ç§€è®¾è®¡ï¼‰
            if response.function_calls:
                tool_call = response.function_calls[0]

                if tool_call.name == "get_akshare_data":
                    interface = tool_call.args.get("interface")
                    params = tool_call.args.get("params", {})

                    logger.info(f"LLMè¯·æ±‚è°ƒç”¨å·¥å…·: interface={interface}, params={params}")

                    if not interface:
                        raise ValueError("LLMæœªæä¾›æ¥å£åç§°")

                    # è°ƒç”¨å®é™…çš„æ•°æ®è·å–å‡½æ•°
                    try:
                        tool_result = await _get_and_normalize_akshare_data(interface, params)

                        # é™åˆ¶è¿”å›ç»™LLMçš„æ•°æ®é‡
                        if isinstance(tool_result, list) and len(tool_result) > 50:
                            tool_result = tool_result[:50] + [{"message": "... (æ•°æ®å·²æˆªæ–­ï¼Œä»…æ˜¾ç¤ºå‰50æ¡)"}]

                    except Exception as e:
                        error_message = f"æ•°æ®è·å–å¤±è´¥: {str(e)}"
                        logger.error(error_message)
                        tool_result = {"error": error_message}

                    # å‘é€å·¥å…·ç»“æœå›LLMï¼ˆä½¿ç”¨æ—§ç‰ˆæœ¬çš„æ–¹æ³•ï¼‰
                    response = chat_session.send_message(
                        Part.from_function_response(
                            name="get_akshare_data",
                            response={"data": tool_result},
                        )
                    )

                final_text = response.text
            else:
                # æ— éœ€å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›LLMå“åº”
                final_text = response.text

            # è§£æLLMå“åº”å¹¶æ„å»ºç»“æ„åŒ–ç»“æœ
            return self._parse_llm_response(final_text, query)

        except Exception as e:
            logger.error(f"LLMåˆ†æå¤±è´¥: {e}")
            # å›é€€åˆ°åŸºäºè§„åˆ™çš„åˆ†æ
            return await self._analyze_with_rules(query, username)

    async def _analyze_with_rules(self, query: str, username: str = None) -> AnalysisResult:
        """ä½¿ç”¨åŸºäºè§„åˆ™çš„åˆ†æï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        # 1. æ„å›¾è¯†åˆ«
        context = self._identify_intent(query)
        self._last_context = context
        logger.info(f"è¯†åˆ«æ„å›¾: {context.intent.value}, ç½®ä¿¡åº¦: {context.confidence}")

        # 2. è·å–ç›¸å…³æ•°æ®
        data_responses = await self._fetch_relevant_data(context, username)

        # 3. æ•°æ®åˆ†æ
        analysis_result = await self._analyze_data(context, data_responses)

        # 4. ç”Ÿæˆå»ºè®®
        analysis_result = self._generate_recommendations(context, analysis_result)

        return analysis_result

    def _parse_llm_response(self, llm_text: str, original_query: str) -> AnalysisResult:
        """è§£æLLMå“åº”å¹¶æ„å»ºç»“æ„åŒ–ç»“æœ"""
        try:
            # å°è¯•ä»LLMå“åº”ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯
            insights = []
            recommendations = []
            data_points = {}
            charts_suggested = []
            risk_level = "ä¸­ç­‰é£é™©"

            # ç®€å•çš„æ–‡æœ¬è§£æé€»è¾‘
            lines = llm_text.split('\n')
            current_section = None

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # è¯†åˆ«ä¸åŒçš„éƒ¨åˆ†
                if any(keyword in line for keyword in ['åˆ†æ', 'æ´å¯Ÿ', 'å‘ç°']):
                    current_section = 'insights'
                elif any(keyword in line for keyword in ['å»ºè®®', 'æ¨è', 'ç­–ç•¥']):
                    current_section = 'recommendations'
                elif any(keyword in line for keyword in ['é£é™©', 'é£é™©ç­‰çº§']):
                    if 'é«˜é£é™©' in line:
                        risk_level = "é«˜é£é™©"
                    elif 'ä½é£é™©' in line:
                        risk_level = "ä½é£é™©"
                    else:
                        risk_level = "ä¸­ç­‰é£é™©"

                # æå–è¦ç‚¹
                if line.startswith(('â€¢', '-', '*', '1.', '2.', '3.')):
                    content = re.sub(r'^[â€¢\-*\d\.]\s*', '', line)
                    if current_section == 'insights':
                        insights.append(content)
                    elif current_section == 'recommendations':
                        recommendations.append(content)

            # å¦‚æœæ²¡æœ‰æå–åˆ°ç»“æ„åŒ–ä¿¡æ¯ï¼Œä½¿ç”¨æ•´ä¸ªå“åº”ä½œä¸ºæ‘˜è¦
            if not insights and not recommendations:
                insights = [llm_text[:200] + "..." if len(llm_text) > 200 else llm_text]

            # æ ¹æ®æŸ¥è¯¢å†…å®¹å»ºè®®å›¾è¡¨ç±»å‹
            if any(keyword in original_query for keyword in ['è‚¡ç¥¨', 'ä»·æ ¼', 'èµ°åŠ¿']):
                charts_suggested = ["ä»·æ ¼èµ°åŠ¿å›¾", "æˆäº¤é‡å›¾"]
            elif any(keyword in original_query for keyword in ['å¸‚åœº', 'å¤§ç›˜']):
                charts_suggested = ["å¸‚åœºçƒ­åŠ›å›¾", "è¡Œä¸šåˆ†å¸ƒå›¾"]
            elif any(keyword in original_query for keyword in ['è´¢åŠ¡', 'PE', 'PB']):
                charts_suggested = ["è´¢åŠ¡æŒ‡æ ‡å›¾", "ä¼°å€¼å¯¹æ¯”å›¾"]

            return AnalysisResult(
                summary=llm_text[:300] + "..." if len(llm_text) > 300 else llm_text,
                insights=insights[:5],  # é™åˆ¶æ•°é‡
                recommendations=recommendations[:5],
                data_points=data_points,
                charts_suggested=charts_suggested,
                risk_level=risk_level,
                confidence=0.9  # LLMåˆ†æçš„ç½®ä¿¡åº¦è¾ƒé«˜
            )

        except Exception as e:
            logger.error(f"è§£æLLMå“åº”å¤±è´¥: {e}")
            return AnalysisResult(
                summary=llm_text,
                insights=["LLMåˆ†æå®Œæˆ"],
                recommendations=["è¯·å‚è€ƒåˆ†æå†…å®¹"],
                data_points={},
                charts_suggested=[],
                risk_level="æœªçŸ¥",
                confidence=0.7
            )
    
    def _identify_intent(self, query: str) -> AnalysisContext:
        """è¯†åˆ«ç”¨æˆ·æ„å›¾"""
        best_intent = IntentType.UNKNOWN
        best_confidence = 0.0
        entities = {}
        
        for intent_type, patterns in self.intent_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, query, re.IGNORECASE)
                if match:
                    confidence = 0.8  # åŸºç¡€ç½®ä¿¡åº¦
                    
                    # æå–å®ä½“
                    if match.groups():
                        entities.update({
                            f"entity_{i}": group 
                            for i, group in enumerate(match.groups()) if group
                        })
                        confidence += 0.1  # æœ‰å®ä½“æå–åŠ åˆ†
                    
                    if confidence > best_confidence:
                        best_confidence = confidence
                        best_intent = intent_type
        
        # æå–è‚¡ç¥¨ä»£ç 
        stock_codes = re.findall(r'\b([0-9]{6})\b', query)
        if stock_codes:
            entities['stock_codes'] = stock_codes
        
        # æå–æ—¶é—´èŒƒå›´
        time_patterns = [
            r'(\d{4})å¹´',
            r'æœ€è¿‘(\d+)å¤©',
            r'è¿‘(\d+)ä¸ªæœˆ',
            r'ä»Šå¹´',
            r'å»å¹´'
        ]
        
        for pattern in time_patterns:
            match = re.search(pattern, query)
            if match:
                entities['time_range'] = match.group()
                break
        
        return AnalysisContext(
            intent=best_intent,
            entities=entities,
            confidence=best_confidence,
            raw_query=query
        )
    
    async def _fetch_relevant_data(self, context: AnalysisContext, username: str) -> List[PaginatedDataResponse]:
        """æ ¹æ®æ„å›¾è·å–ç›¸å…³æ•°æ®"""
        data_responses = []
        
        # æ ¹æ®æ„å›¾ç±»å‹ç¡®å®šéœ€è¦çš„æ•°æ®
        template = self.analysis_templates.get(context.intent, {})
        required_interfaces = template.get("required_data", [])
        
        # å¦‚æœæœ‰è‚¡ç¥¨ä»£ç ï¼Œè·å–è‚¡ç¥¨æ•°æ®
        if 'stock_codes' in context.entities:
            for stock_code in context.entities['stock_codes']:
                for interface in required_interfaces:
                    try:
                        request = MCPRequest(
                            interface=interface,
                            params=self._build_params(interface, stock_code, context),
                            request_id=f"llm_analysis_{interface}_{stock_code}"
                        )
                        
                        response = await handle_mcp_data_request(request, 1, 100, username)
                        data_responses.append(response)
                        
                    except Exception as e:
                        logger.warning(f"è·å–æ•°æ®å¤±è´¥ {interface}: {e}")
        
        # å¦‚æœæ˜¯å¸‚åœºæ¦‚è§ˆï¼Œè·å–å¸‚åœºæ•°æ®
        elif context.intent == IntentType.MARKET_OVERVIEW:
            try:
                request = MCPRequest(
                    interface="stock_zh_a_spot_em",
                    params={},
                    request_id="llm_analysis_market_overview"
                )
                response = await handle_mcp_data_request(request, 1, 100, username)
                data_responses.append(response)
            except Exception as e:
                logger.warning(f"è·å–å¸‚åœºæ•°æ®å¤±è´¥: {e}")
        
        return data_responses
    
    def _build_params(self, interface: str, stock_code: str, context: AnalysisContext) -> Dict[str, Any]:
        """æ„å»ºæ¥å£å‚æ•°"""
        params = {}
        
        if interface == "stock_zh_a_hist":
            params = {
                "symbol": stock_code,
                "period": "daily",
                "start_date": "20240101",  # é»˜è®¤ä»Šå¹´æ•°æ®
                "end_date": "20241231"
            }
        elif interface == "stock_zh_a_spot_em":
            params = {}
        elif interface == "stock_yjbb_em":
            params = {"date": "2024"}
        
        # æ ¹æ®æ—¶é—´èŒƒå›´è°ƒæ•´å‚æ•°
        if 'time_range' in context.entities:
            time_range = context.entities['time_range']
            if "æœ€è¿‘" in time_range and "å¤©" in time_range:
                days = re.search(r'(\d+)', time_range)
                if days:
                    from datetime import datetime, timedelta
                    end_date = datetime.now()
                    start_date = end_date - timedelta(days=int(days.group(1)))
                    params.update({
                        "start_date": start_date.strftime("%Y%m%d"),
                        "end_date": end_date.strftime("%Y%m%d")
                    })
        
        return params

    async def _analyze_data(self, context: AnalysisContext, data_responses: List[PaginatedDataResponse]) -> AnalysisResult:
        """åˆ†ææ•°æ®å¹¶ç”Ÿæˆæ´å¯Ÿ"""
        insights = []
        data_points = {}
        charts_suggested = []

        if not data_responses:
            return AnalysisResult(
                summary="æœªè·å–åˆ°ç›¸å…³æ•°æ®",
                insights=["æ•°æ®è·å–å¤±è´¥"],
                recommendations=[],
                data_points={},
                charts_suggested=[],
                risk_level="æœªçŸ¥",
                confidence=0.0
            )

        # åˆ†ææ¯ä¸ªæ•°æ®å“åº”
        for response in data_responses:
            if response.data:
                df = pd.DataFrame(response.data)

                # æ ¹æ®æ„å›¾ç±»å‹è¿›è¡Œä¸åŒçš„åˆ†æ
                if context.intent == IntentType.STOCK_ANALYSIS:
                    insights.extend(self._analyze_stock_data(df, data_points))
                    charts_suggested.extend(["ä»·æ ¼èµ°åŠ¿å›¾", "æˆäº¤é‡å›¾", "æŠ€æœ¯æŒ‡æ ‡å›¾"])

                elif context.intent == IntentType.MARKET_OVERVIEW:
                    insights.extend(self._analyze_market_data(df, data_points))
                    charts_suggested.extend(["å¸‚åœºçƒ­åŠ›å›¾", "è¡Œä¸šåˆ†å¸ƒå›¾", "æ¶¨è·Œåˆ†å¸ƒå›¾"])

                elif context.intent == IntentType.FINANCIAL_METRICS:
                    insights.extend(self._analyze_financial_data(df, data_points))
                    charts_suggested.extend(["è´¢åŠ¡æŒ‡æ ‡é›·è¾¾å›¾", "åŒè¡Œå¯¹æ¯”å›¾"])

        # ç”Ÿæˆåˆ†ææ‘˜è¦
        summary = self._generate_summary(context, insights, data_points)

        # è¯„ä¼°é£é™©ç­‰çº§
        risk_level = self._assess_risk_level(context, data_points)

        return AnalysisResult(
            summary=summary,
            insights=insights,
            recommendations=[],  # å°†åœ¨ä¸‹ä¸€æ­¥ç”Ÿæˆ
            data_points=data_points,
            charts_suggested=list(set(charts_suggested)),
            risk_level=risk_level,
            confidence=0.8
        )

    def _analyze_stock_data(self, df: pd.DataFrame, data_points: Dict[str, Any]) -> List[str]:
        """åˆ†æè‚¡ç¥¨æ•°æ®"""
        insights = []

        try:
            # æ£€æŸ¥æ•°æ®åˆ—
            if 'æ”¶ç›˜' in df.columns or 'close' in df.columns:
                close_col = 'æ”¶ç›˜' if 'æ”¶ç›˜' in df.columns else 'close'
                prices = df[close_col].astype(float)

                # ä»·æ ¼è¶‹åŠ¿åˆ†æ
                if len(prices) > 1:
                    price_change = (prices.iloc[-1] - prices.iloc[0]) / prices.iloc[0] * 100
                    data_points['price_change_pct'] = round(price_change, 2)

                    if price_change > 5:
                        insights.append(f"è‚¡ä»·å‘ˆç°å¼ºåŠ²ä¸Šæ¶¨è¶‹åŠ¿ï¼Œç´¯è®¡æ¶¨å¹…{price_change:.2f}%")
                    elif price_change > 0:
                        insights.append(f"è‚¡ä»·æ¸©å’Œä¸Šæ¶¨ï¼Œç´¯è®¡æ¶¨å¹…{price_change:.2f}%")
                    elif price_change > -5:
                        insights.append(f"è‚¡ä»·å°å¹…ä¸‹è·Œï¼Œç´¯è®¡è·Œå¹…{abs(price_change):.2f}%")
                    else:
                        insights.append(f"è‚¡ä»·å¤§å¹…ä¸‹è·Œï¼Œç´¯è®¡è·Œå¹…{abs(price_change):.2f}%")

                # æ³¢åŠ¨ç‡åˆ†æ
                if len(prices) > 5:
                    volatility = prices.pct_change().std() * 100
                    data_points['volatility'] = round(volatility, 2)

                    if volatility > 3:
                        insights.append(f"è‚¡ä»·æ³¢åŠ¨è¾ƒå¤§ï¼Œæ—¥å‡æ³¢åŠ¨ç‡{volatility:.2f}%")
                    elif volatility > 1.5:
                        insights.append(f"è‚¡ä»·æ³¢åŠ¨é€‚ä¸­ï¼Œæ—¥å‡æ³¢åŠ¨ç‡{volatility:.2f}%")
                    else:
                        insights.append(f"è‚¡ä»·ç›¸å¯¹ç¨³å®šï¼Œæ—¥å‡æ³¢åŠ¨ç‡{volatility:.2f}%")

            # æˆäº¤é‡åˆ†æ
            if 'æˆäº¤é‡' in df.columns or 'volume' in df.columns:
                volume_col = 'æˆäº¤é‡' if 'æˆäº¤é‡' in df.columns else 'volume'
                volumes = df[volume_col].astype(float)

                if len(volumes) > 5:
                    avg_volume = volumes.mean()
                    recent_volume = volumes.iloc[-5:].mean()
                    volume_ratio = recent_volume / avg_volume

                    data_points['volume_ratio'] = round(volume_ratio, 2)

                    if volume_ratio > 1.5:
                        insights.append("è¿‘æœŸæˆäº¤é‡æ˜æ˜¾æ”¾å¤§ï¼Œå¸‚åœºå…³æ³¨åº¦æå‡")
                    elif volume_ratio < 0.7:
                        insights.append("è¿‘æœŸæˆäº¤é‡èç¼©ï¼Œå¸‚åœºå‚ä¸åº¦ä¸‹é™")
                    else:
                        insights.append("æˆäº¤é‡ä¿æŒæ­£å¸¸æ°´å¹³")

        except Exception as e:
            logger.warning(f"è‚¡ç¥¨æ•°æ®åˆ†æå‡ºé”™: {e}")
            insights.append("æ•°æ®åˆ†æè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸")

        return insights

    def _analyze_market_data(self, df: pd.DataFrame, data_points: Dict[str, Any]) -> List[str]:
        """åˆ†æå¸‚åœºæ•°æ®"""
        insights = []

        try:
            if 'æ¶¨è·Œå¹…' in df.columns:
                change_pct = df['æ¶¨è·Œå¹…'].astype(float)

                # æ¶¨è·Œåˆ†å¸ƒ
                rising_count = (change_pct > 0).sum()
                falling_count = (change_pct < 0).sum()
                total_count = len(change_pct)

                rising_ratio = rising_count / total_count * 100
                data_points['rising_ratio'] = round(rising_ratio, 1)

                if rising_ratio > 70:
                    insights.append(f"å¸‚åœºæƒ…ç»ªä¹è§‚ï¼Œ{rising_ratio:.1f}%çš„è‚¡ç¥¨ä¸Šæ¶¨")
                elif rising_ratio > 50:
                    insights.append(f"å¸‚åœºè¡¨ç°å¹³è¡¡ï¼Œ{rising_ratio:.1f}%çš„è‚¡ç¥¨ä¸Šæ¶¨")
                else:
                    insights.append(f"å¸‚åœºæƒ…ç»ªåå¼±ï¼Œä»…{rising_ratio:.1f}%çš„è‚¡ç¥¨ä¸Šæ¶¨")

                # æ¶¨è·Œå¹…åˆ†å¸ƒ
                strong_rising = (change_pct > 5).sum()
                strong_falling = (change_pct < -5).sum()

                if strong_rising > total_count * 0.1:
                    insights.append(f"æœ‰{strong_rising}åªè‚¡ç¥¨æ¶¨å¹…è¶…è¿‡5%ï¼Œå¸‚åœºæ´»è·ƒåº¦è¾ƒé«˜")

                if strong_falling > total_count * 0.1:
                    insights.append(f"æœ‰{strong_falling}åªè‚¡ç¥¨è·Œå¹…è¶…è¿‡5%ï¼Œéœ€æ³¨æ„é£é™©")

        except Exception as e:
            logger.warning(f"å¸‚åœºæ•°æ®åˆ†æå‡ºé”™: {e}")
            insights.append("å¸‚åœºæ•°æ®åˆ†æè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸")

        return insights

    def _analyze_financial_data(self, df: pd.DataFrame, data_points: Dict[str, Any]) -> List[str]:
        """åˆ†æè´¢åŠ¡æ•°æ®"""
        insights = []

        try:
            # åˆ†æPEã€PBç­‰ä¼°å€¼æŒ‡æ ‡
            if 'PE' in df.columns or 'å¸‚ç›ˆç‡' in df.columns:
                pe_col = 'PE' if 'PE' in df.columns else 'å¸‚ç›ˆç‡'
                pe_values = pd.to_numeric(df[pe_col], errors='coerce').dropna()

                if not pe_values.empty:
                    avg_pe = pe_values.mean()
                    data_points['avg_pe'] = round(avg_pe, 2)

                    if avg_pe > 30:
                        insights.append(f"å¹³å‡å¸‚ç›ˆç‡{avg_pe:.1f}å€ï¼Œä¼°å€¼åé«˜")
                    elif avg_pe > 15:
                        insights.append(f"å¹³å‡å¸‚ç›ˆç‡{avg_pe:.1f}å€ï¼Œä¼°å€¼åˆç†")
                    else:
                        insights.append(f"å¹³å‡å¸‚ç›ˆç‡{avg_pe:.1f}å€ï¼Œä¼°å€¼åä½")

            # åˆ†æROEç­‰ç›ˆåˆ©æŒ‡æ ‡
            if 'ROE' in df.columns or 'å‡€èµ„äº§æ”¶ç›Šç‡' in df.columns:
                roe_col = 'ROE' if 'ROE' in df.columns else 'å‡€èµ„äº§æ”¶ç›Šç‡'
                roe_values = pd.to_numeric(df[roe_col], errors='coerce').dropna()

                if not roe_values.empty:
                    avg_roe = roe_values.mean()
                    data_points['avg_roe'] = round(avg_roe, 2)

                    if avg_roe > 15:
                        insights.append(f"å‡€èµ„äº§æ”¶ç›Šç‡{avg_roe:.1f}%ï¼Œç›ˆåˆ©èƒ½åŠ›å¼º")
                    elif avg_roe > 10:
                        insights.append(f"å‡€èµ„äº§æ”¶ç›Šç‡{avg_roe:.1f}%ï¼Œç›ˆåˆ©èƒ½åŠ›è‰¯å¥½")
                    else:
                        insights.append(f"å‡€èµ„äº§æ”¶ç›Šç‡{avg_roe:.1f}%ï¼Œç›ˆåˆ©èƒ½åŠ›ä¸€èˆ¬")

        except Exception as e:
            logger.warning(f"è´¢åŠ¡æ•°æ®åˆ†æå‡ºé”™: {e}")
            insights.append("è´¢åŠ¡æ•°æ®åˆ†æè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸")

        return insights

    def _generate_summary(self, context: AnalysisContext, insights: List[str], data_points: Dict[str, Any]) -> str:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        if context.intent == IntentType.STOCK_ANALYSIS:
            stock_codes = context.entities.get('stock_codes', ['ç›®æ ‡è‚¡ç¥¨'])
            stock_name = stock_codes[0] if stock_codes else "ç›®æ ‡è‚¡ç¥¨"

            if 'price_change_pct' in data_points:
                change = data_points['price_change_pct']
                trend = "ä¸Šæ¶¨" if change > 0 else "ä¸‹è·Œ"
                return f"{stock_name}è¿‘æœŸå‘ˆç°{trend}è¶‹åŠ¿ï¼Œç´¯è®¡å˜åŠ¨{abs(change):.2f}%ã€‚" + \
                       f"åŸºäºæŠ€æœ¯åˆ†æï¼Œè¯¥è‚¡ç¥¨{'è¡¨ç°å¼ºåŠ²' if change > 5 else 'è¡¨ç°å¹³ç¨³' if change > -5 else 'æ‰¿å‹æ˜æ˜¾'}ã€‚"
            else:
                return f"å¯¹{stock_name}çš„åˆ†ææ˜¾ç¤ºï¼Œéœ€è¦æ›´å¤šæ•°æ®æ¥åšå‡ºå‡†ç¡®åˆ¤æ–­ã€‚"

        elif context.intent == IntentType.MARKET_OVERVIEW:
            if 'rising_ratio' in data_points:
                ratio = data_points['rising_ratio']
                sentiment = "ä¹è§‚" if ratio > 60 else "è°¨æ…" if ratio > 40 else "æ‚²è§‚"
                return f"å½“å‰å¸‚åœºæ•´ä½“æƒ…ç»ª{sentiment}ï¼Œ{ratio:.1f}%çš„è‚¡ç¥¨å®ç°ä¸Šæ¶¨ã€‚" + \
                       f"å¸‚åœº{'æ´»è·ƒåº¦è¾ƒé«˜' if ratio > 60 else 'è¡¨ç°å¹³è¡¡' if ratio > 40 else 'æ‰¿å‹æ˜æ˜¾'}ã€‚"
            else:
                return "å¸‚åœºæ•´ä½“åˆ†ææ˜¾ç¤ºï¼Œå½“å‰å¤„äºéœ‡è¡è°ƒæ•´é˜¶æ®µã€‚"

        elif context.intent == IntentType.FINANCIAL_METRICS:
            return "è´¢åŠ¡æŒ‡æ ‡åˆ†ææ˜¾ç¤ºï¼Œ" + "ï¼Œ".join(insights[:2]) if insights else "è´¢åŠ¡æ•°æ®åˆ†æå®Œæˆã€‚"

        else:
            return "åŸºäºå½“å‰æ•°æ®çš„åˆ†æå·²å®Œæˆï¼Œ" + "ï¼Œ".join(insights[:2]) if insights else "åˆ†æç»“æœæœ‰é™ã€‚"

    def _assess_risk_level(self, context: AnalysisContext, data_points: Dict[str, Any]) -> str:
        """è¯„ä¼°é£é™©ç­‰çº§"""
        risk_score = 0

        # åŸºäºæ³¢åŠ¨ç‡è¯„ä¼°é£é™©
        if 'volatility' in data_points:
            volatility = data_points['volatility']
            if volatility > 3:
                risk_score += 3
            elif volatility > 1.5:
                risk_score += 2
            else:
                risk_score += 1

        # åŸºäºä»·æ ¼å˜åŠ¨è¯„ä¼°é£é™©
        if 'price_change_pct' in data_points:
            change = abs(data_points['price_change_pct'])
            if change > 10:
                risk_score += 3
            elif change > 5:
                risk_score += 2
            else:
                risk_score += 1

        # åŸºäºå¸‚åœºæƒ…ç»ªè¯„ä¼°é£é™©
        if 'rising_ratio' in data_points:
            ratio = data_points['rising_ratio']
            if ratio < 30 or ratio > 80:
                risk_score += 2
            else:
                risk_score += 1

        # è½¬æ¢ä¸ºé£é™©ç­‰çº§
        if risk_score >= 7:
            return "é«˜é£é™©"
        elif risk_score >= 4:
            return "ä¸­ç­‰é£é™©"
        else:
            return "ä½é£é™©"

    def _generate_recommendations(self, context: AnalysisContext, analysis_result: AnalysisResult) -> AnalysisResult:
        """ç”ŸæˆæŠ•èµ„å»ºè®®"""
        recommendations = []

        # åŸºäºæ„å›¾ç±»å‹ç”Ÿæˆå»ºè®®
        if context.intent == IntentType.STOCK_ANALYSIS:
            recommendations.extend(self._generate_stock_recommendations(analysis_result))

        elif context.intent == IntentType.MARKET_OVERVIEW:
            recommendations.extend(self._generate_market_recommendations(analysis_result))

        elif context.intent == IntentType.FINANCIAL_METRICS:
            recommendations.extend(self._generate_financial_recommendations(analysis_result))

        else:
            recommendations.extend(self._generate_general_recommendations(analysis_result))

        # åŸºäºé£é™©ç­‰çº§æ·»åŠ é£é™©æç¤º
        if analysis_result.risk_level == "é«˜é£é™©":
            recommendations.append("âš ï¸ å½“å‰é£é™©ç­‰çº§è¾ƒé«˜ï¼Œå»ºè®®è°¨æ…æŠ•èµ„ï¼Œåšå¥½é£é™©æ§åˆ¶")
        elif analysis_result.risk_level == "ä¸­ç­‰é£é™©":
            recommendations.append("âš¡ å½“å‰å­˜åœ¨ä¸€å®šé£é™©ï¼Œå»ºè®®é€‚åº¦é…ç½®ï¼Œåˆ†æ•£æŠ•èµ„")
        else:
            recommendations.append("âœ… å½“å‰é£é™©ç›¸å¯¹è¾ƒä½ï¼Œå¯è€ƒè™‘é€‚å½“é…ç½®")

        analysis_result.recommendations = recommendations
        return analysis_result

    def _generate_stock_recommendations(self, analysis_result: AnalysisResult) -> List[str]:
        """ç”Ÿæˆè‚¡ç¥¨æŠ•èµ„å»ºè®®"""
        recommendations = []
        data_points = analysis_result.data_points

        if 'price_change_pct' in data_points:
            change = data_points['price_change_pct']

            if change > 10:
                recommendations.append("ğŸ“ˆ è‚¡ä»·æ¶¨å¹…è¾ƒå¤§ï¼Œå»ºè®®å…³æ³¨å›è°ƒé£é™©ï¼Œå¯è€ƒè™‘åˆ†æ‰¹å‡ä»“")
            elif change > 5:
                recommendations.append("ğŸ“Š è‚¡ä»·è¡¨ç°è‰¯å¥½ï¼Œå¯ç»§ç»­æŒæœ‰ï¼Œæ³¨æ„è®¾ç½®æ­¢ç›ˆç‚¹")
            elif change > 0:
                recommendations.append("ğŸ“‰ è‚¡ä»·æ¸©å’Œä¸Šæ¶¨ï¼Œå¯é€‚å½“åŠ ä»“ï¼Œä½†éœ€æ§åˆ¶ä»“ä½")
            elif change > -5:
                recommendations.append("ğŸ” è‚¡ä»·å°å¹…ä¸‹è·Œï¼Œå¯å…³æ³¨æ”¯æ’‘ä½ï¼Œå¯»æ‰¾ä¹°å…¥æœºä¼š")
            else:
                recommendations.append("âš ï¸ è‚¡ä»·è·Œå¹…è¾ƒå¤§ï¼Œå»ºè®®ç­‰å¾…ä¼ç¨³ä¿¡å·å†è€ƒè™‘ä»‹å…¥")

        if 'volatility' in data_points:
            volatility = data_points['volatility']
            if volatility > 3:
                recommendations.append("ğŸ¢ æ³¢åŠ¨ç‡è¾ƒé«˜ï¼Œå»ºè®®é‡‡ç”¨åˆ†æ‰¹å»ºä»“ç­–ç•¥ï¼Œé™ä½é£é™©")

        if 'volume_ratio' in data_points:
            volume_ratio = data_points['volume_ratio']
            if volume_ratio > 1.5:
                recommendations.append("ğŸ“Š æˆäº¤é‡æ”¾å¤§ï¼Œå…³æ³¨èµ„é‡‘æµå‘ï¼Œå¯èƒ½æœ‰é‡è¦æ¶ˆæ¯")
            elif volume_ratio < 0.7:
                recommendations.append("ğŸ“‰ æˆäº¤é‡èç¼©ï¼Œå¸‚åœºå…³æ³¨åº¦ä¸é«˜ï¼Œéœ€è°¨æ…æ“ä½œ")

        return recommendations

    def _generate_market_recommendations(self, analysis_result: AnalysisResult) -> List[str]:
        """ç”Ÿæˆå¸‚åœºæŠ•èµ„å»ºè®®"""
        recommendations = []
        data_points = analysis_result.data_points

        if 'rising_ratio' in data_points:
            ratio = data_points['rising_ratio']

            if ratio > 70:
                recommendations.append("ğŸš€ å¸‚åœºæƒ…ç»ªä¹è§‚ï¼Œå¯é€‚å½“å¢åŠ ä»“ä½ï¼Œä½†éœ€é˜²èŒƒè¿‡çƒ­é£é™©")
            elif ratio > 50:
                recommendations.append("âš–ï¸ å¸‚åœºè¡¨ç°å‡è¡¡ï¼Œå»ºè®®ä¿æŒç°æœ‰é…ç½®ï¼Œè§‚å¯Ÿåç»­èµ°åŠ¿")
            else:
                recommendations.append("ğŸ›¡ï¸ å¸‚åœºæƒ…ç»ªåå¼±ï¼Œå»ºè®®é™ä½ä»“ä½ï¼Œç­‰å¾…æ›´å¥½æ—¶æœº")

        recommendations.append("ğŸ”„ å»ºè®®å…³æ³¨è¡Œä¸šè½®åŠ¨æœºä¼šï¼Œåˆ†æ•£æŠ•èµ„é™ä½é£é™©")
        recommendations.append("ğŸ“… å®šæœŸå…³æ³¨å®è§‚ç»æµæ•°æ®å’Œæ”¿ç­–å˜åŒ–")

        return recommendations

    def _generate_financial_recommendations(self, analysis_result: AnalysisResult) -> List[str]:
        """ç”Ÿæˆè´¢åŠ¡åˆ†æå»ºè®®"""
        recommendations = []
        data_points = analysis_result.data_points

        if 'avg_pe' in data_points:
            pe = data_points['avg_pe']
            if pe > 30:
                recommendations.append("ğŸ“Š ä¼°å€¼åé«˜ï¼Œå»ºè®®ç­‰å¾…å›è°ƒæˆ–å¯»æ‰¾ä½ä¼°å€¼æ ‡çš„")
            elif pe < 15:
                recommendations.append("ğŸ’ ä¼°å€¼ç›¸å¯¹è¾ƒä½ï¼Œå¯å…³æ³¨åŸºæœ¬é¢æ”¹å–„çš„æŠ•èµ„æœºä¼š")

        if 'avg_roe' in data_points:
            roe = data_points['avg_roe']
            if roe > 15:
                recommendations.append("â­ ç›ˆåˆ©èƒ½åŠ›å¼ºï¼Œå¯é‡ç‚¹å…³æ³¨æ­¤ç±»ä¼˜è´¨æ ‡çš„")
            elif roe < 10:
                recommendations.append("âš ï¸ ç›ˆåˆ©èƒ½åŠ›ä¸€èˆ¬ï¼Œéœ€ç»“åˆå…¶ä»–æŒ‡æ ‡ç»¼åˆåˆ¤æ–­")

        recommendations.append("ğŸ“ˆ å»ºè®®å…³æ³¨è´¢åŠ¡æŒ‡æ ‡çš„è¶‹åŠ¿å˜åŒ–ï¼Œè€Œéå•ä¸€æ—¶ç‚¹æ•°æ®")

        return recommendations

    def _generate_general_recommendations(self, analysis_result: AnalysisResult) -> List[str]:
        """ç”Ÿæˆé€šç”¨å»ºè®®"""
        return [
            "ğŸ“Š å»ºè®®ç»“åˆå¤šä¸ªç»´åº¦çš„æ•°æ®è¿›è¡Œç»¼åˆåˆ†æ",
            "â° ä¿æŒé•¿æœŸæŠ•èµ„è§†è§’ï¼Œé¿å…çŸ­æœŸæƒ…ç»ªåŒ–æ“ä½œ",
            "ğŸ¯ æ ¹æ®ä¸ªäººé£é™©æ‰¿å—èƒ½åŠ›åˆ¶å®šæŠ•èµ„ç­–ç•¥",
            "ğŸ“š æŒç»­å­¦ä¹ å’Œå…³æ³¨å¸‚åœºåŠ¨æ€"
        ]

# åˆ›å»ºå…¨å±€å®ä¾‹
# ä¼˜å…ˆä½¿ç”¨LLMæ¨¡å¼ï¼Œå¦‚æœä¸å¯ç”¨åˆ™å›é€€åˆ°è§„åˆ™æ¨¡å¼
llm_analysis_handler = LLMAnalysisHandler(use_llm=True)

# åˆ›å»ºä»…ä½¿ç”¨è§„åˆ™çš„å®ä¾‹ï¼ˆç”¨äºå¯¹æ¯”æµ‹è¯•ï¼‰
rule_based_handler = LLMAnalysisHandler(use_llm=False)
